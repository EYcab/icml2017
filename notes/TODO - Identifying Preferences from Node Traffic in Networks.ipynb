{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking and Preferences\n",
    "\n",
    "Tues, Aug 8, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ChoiceRank: Identifying Preferences from Node Traffic in Networks\n",
    "\n",
    "Lucas Maystre (EPFL)\n",
    "\n",
    "[Matt Grossglauser](https://2017.icml.cc/Conferences/2017/Schedule?showSpeaker=7108-1280) (EPFL)\n",
    "\n",
    "*Understanding how users navigate in a network is of high interest in many applications. We consider a setting where only aggregate node-level traffic is observed and tackle the task of learning edge transition probabilities. We cast it as a preference learning problem, and we study a model where choices follow Luce's axiom. In this case, the $\\mathcal{O}(n)$ marginal counts of node visits are a sufficient statistic for the $\\mathcal{O}(n^{2})$ transition probabilities. We show how to make the inference problem well-posed regardless of the network's structure, and we present ChoiceRank, an iterative algorithm that scales to networks that contains billions of nodes and edges. We apply the model to two clickstream datasets and show that it successfully recovers the transition probabilities using only the network structure and marginal (node-level) traffic data. Finally, we also consider an application to mobility networks and apply the model to one year of rides on New York City's bicycle-sharing system.*\n",
    "\n",
    "- Want to understand how users network on Wikipedia\n",
    "- Based on network traffic data and embedded links, can we estimate how people navigate?\n",
    "\n",
    "- can come up with probability distribution of how users navigate the edges (nodes) in a network based on 1) network structure and 2) marginal network information (popularity of page, etc.)\n",
    "\n",
    "- Luce's choice axiom postulates there's some latent utility parameter, lambda, and transitions from i -> j are proportional to the utility of page j.\n",
    "\n",
    "inverting a steady-state\n",
    "\n",
    "kumar et al. WSDM 2015\n",
    "\n",
    "choicerank assumes discrete choices are made on a network:\n",
    "\n",
    "works with finite traffic, arbitrary network structure\n",
    "\n",
    "- Given network structure + marginal traffic, find \"good\" parameters lambda\n",
    "\n",
    "Pretend that we can observe all trandisions in a network... given the probabilisitc estimates of transitions, we can determine the log likelihood of the model\n",
    "\n",
    "marginal traffic {(ci+,ci-)|i \\in V} is a minimally sufficient statistic for lambda\n",
    "\n",
    "theorem: if a > 1 and B > 0, there is always a unique maximum\n",
    "\n",
    "maximize the log-posterior using the MM algorithm (Hunter 2004)\n",
    "\n",
    "Scales very well to large graphs. 3.5B nodes, 128 B edges, takes 20 min/iteration on a recent machine\n",
    "\n",
    "### Applications\n",
    "Where would you use this?\n",
    "\n",
    "- Understanding how users transition in a network\n",
    "- Areas where cost to monitor or privacy is not paramount\n",
    "\n",
    "__Code__:\n",
    "1. [Choicerank codebase](https://github.com/lucasmaystre/choicerank)\n",
    "2. [Choicerank example notebook](https://github.com/lucasmaystre/choix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Inference for Incomplete Ranking Data: The Case of Rank-Dependent Coarsening\n",
    "\n",
    "*We consider the problem of statistical inference for ranking data, specifically rank aggregation, under the assumption that samples are incomplete in the sense of not comprising all choice alternatives. In contrast to most existing methods, we explicitly model the process of turning a full ranking into an incomplete one, which we call the coarsening process. To this end, we propose the concept of rank-dependent coarsening, which assumes that incomplete rankings are produced by projecting a full ranking to a random subset of ranks. For a concrete instantiation of our model, in which full rankings are drawn from a Plackett-Luce distribution and observations take the form of pairwise preferences, we study the performance of various rank aggregation methods. In addition to predictive accuracy in the finite sample setting, we address the theoretical question of consistency, by which we mean the ability to recover a target ranking when the sample size goes to infinity, despite a potential bias in the observations caused by the (unknown) coarsening.*\n",
    "\n",
    "Study the problem of rank aggregation\n",
    "\n",
    "Given ranking over set of items, combine ranking into a single consensus ranking\n",
    "\n",
    "Plackett-luce for the probability assigned to ranking \\pi given parameter vector \\theta\n",
    "\n",
    "Bradley-Terry-Luce model\n",
    "\n",
    "In most applications, the observed rankings are incomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Just Sort It! A Simple and Effective Approach to Active Preference Learning\n",
    "\n",
    "*We address the problem of learning a ranking by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort. But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking? We give favorable guarantees for Quicksort for the popular Bradley-Terry model, under natural assumptions on the parameters. Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items. This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.*\n",
    "\n",
    "Lucas Maystre (EPFL)\n",
    "\n",
    "[Matt Grossglauser](https://2017.icml.cc/Conferences/2017/Schedule?showSpeaker=7108-1280) (EPFL)\n",
    "\n",
    "Goal: learning a ranking from noisy pairwise comparisons\n",
    "  - Some outcomes are inconsistent with the ranking\n",
    "  \n",
    "Recover the ranking accurately, but sample sparingly\n",
    "  - Choose pairs of items adaptively based on previous observations\n",
    "  \n",
    "Consider gifgif website\n",
    "  - Given two images, which better expresses <some_emotion>\n",
    "  \n",
    "Idea:\n",
    "  - Use a sorting algorithm\n",
    "  - In the case where every comparison outcome is consistent with a ranking, provide best adaptive schedule of pairwise comparisons\n",
    "\n",
    "### Applications\n",
    "\n",
    "Do all pairwise similarities *need* to be compared? Or can they be sampled? This might have implications for BOA at State Farm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
